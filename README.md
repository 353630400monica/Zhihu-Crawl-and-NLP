#基于python的网站语料采集系统及自然语言处理
## Introduce

### zhihu_question_redis

>Distributed crawler based on Redis
>>以知乎网站的[话题广场](https://www.zhihu.com/topics)为入口，以话题为单位爬取知乎上的问题(包括问题内容、关注数、浏览数、回答数等信息)

### zhihui_redis

>Distributed crawler based on Redis
>>以知乎网站的[话题广场](https://www.zhihu.com/topics)为入口，以话题为单位爬取知乎上的问题(包括问题内容、关注数、浏览数、回答数等信息)，以及问题下面的回答(包括回答内容、回答点赞数、回答评论数等信息)

### NLPWork
>Use the crawled data to perform some interesting natural language processing tasks<br>
>>Research whether there is a liner relationship between the number of attention(关注数), the number of views(浏览数), and the number of answers(回答数) to the questions from ZhiHu.
>>Research the questions with a high number of answers, extract the keywords from them, and form a word cloud<br>
>>Use FastText model and TextRNN model to classify text





## Reference
https://github.com/649453932/Chinese-Text-Classification-Pytorch

## Contact
353630400@qq.com<br>
